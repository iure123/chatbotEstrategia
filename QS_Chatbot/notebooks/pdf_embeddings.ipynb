{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/iuremorais/AppData/Local/Microsoft/WindowsApps/python3.12.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from google.cloud import firestore\n",
    "from google.cloud.firestore_v1.base_vector_query import DistanceMeasure\n",
    "from google.cloud.firestore_v1.vector import Vector\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "from suzano.data_connections.google_storage import GoogleStorageConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=\"sz-academia-digital-feat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload de Arquivo no Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_storage = GoogleStorageConnection(\n",
    "    project_id_str=\"sz-academia-digital-feat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"pdf/Prompt_Produto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_storage.upload_file(\n",
    "    \"storage-qs-chatbot-feat\",\n",
    "    source_path_str=file_path,\n",
    "    destination_path_str=file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = [file for file in db_storage.storage_client.list_blobs(\"storage-qs-chatbot-feat\") if file.name == file_path]\n",
    "file_uri = 'gs://' + file[0].id[:-(len(str(file[0].generation)) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catalogar arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(file_uri):\n",
    "  model = GenerativeModel(\n",
    "    \"gemini-1.5-pro-001\",\n",
    "    system_instruction=\"Formate a resposta com um único JSON, acessível via json.loads python, como no exemplo: '[{\\\"page\\\": \\\"__PAGINA__\\\",  \\\"content\\\": \\\"__CONTEUDO_PAGINA__\\\"}]'\"\n",
    "  )\n",
    "\n",
    "  responses = model.generate_content(\n",
    "    [\n",
    "      Part.from_uri(file_uri, mime_type=\"application/pdf\"),\n",
    "      \"\"\"\"Catalogue o documento, separe por página, e em cada item traga a página e conteúdo. Em caso de imagens ou tabelas sumarize a informação como texto.\"\"\"\n",
    "    ],\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 1,\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "    },\n",
    "    safety_settings={\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    },\n",
    "    stream=False,\n",
    "  )\n",
    "\n",
    "  return responses.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate(file_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando Vector Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"textembedding-gecko@003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextEmbeddingModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc = pd.DataFrame(catalog)\n",
    "df_loc[\"file_uri\"] = file_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [ TextEmbeddingInput(row[\"content\"], \"RETRIEVAL_QUERY\") for _, row in df_loc.iterrows() ]\n",
    "embeddings = model.get_embeddings(inputs)\n",
    "embed_db = { idx: Vector(embedding.values) for idx, embedding in enumerate(embeddings) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc[\"embeddings\"] = df_loc.index.map(embed_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando ao Firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firestore_client = firestore.Client(\"sz-academia-digital-feat\")\n",
    "collection = firestore_client.collection(\"qs-chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in df_loc.to_dict(orient=\"records\"):\n",
    "    collection.add(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Busca Vetorizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Como uma solução digital pode reduzir custos operacionais e melhorar a eficiência?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [TextEmbeddingInput(text, \"RETRIEVAL_QUERY\") for text in [ query ]]\n",
    "embeddings = model.get_embeddings(inputs)\n",
    "embed_ask = [Vector(embedding.values) for embedding in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_ask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = collection.find_nearest(\n",
    "   vector_field=\"embeddings\",\n",
    "   query_vector=embed_ask[0],\n",
    "   distance_measure=DistanceMeasure.EUCLIDEAN,\n",
    "   limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gcloud alpha firestore indexes composite create --project=sz-academia-digital-feat --collection-group=qs-chatbot --query-scope=COLLECTION --field-config=vector-config='{\"dimension\":\"768\",\"flat\": \"{}\"}',field-path=embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [item.to_dict() for item in response.get()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qs-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
